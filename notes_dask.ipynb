{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "882a6dbd-e185-4cc1-a32d-bc7daf34aa68",
   "metadata": {},
   "source": [
    "# Using Dask \"Locally\" on a Virtual Machine\n",
    "I'm using this document to keep track of some different methods for applying Dask in data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3724f9d9-9271-4b78-8027-0b5e6775e564",
   "metadata": {},
   "source": [
    "## 1. Clusters and Clients\n",
    "\n",
    "* A dask *Cluster* is a collection of workers/cores/threads that do the parallel computations.\n",
    "* A `worker` is a separate 'machine' in the cluster. It can still be comprised of threads and cores.\n",
    "* A cluster can either represent a set of remote machines or a partition of your local system (or VM) into workers.\n",
    "* By default a cluster is set up with the number of available cores on the system.\n",
    "* Clusters are part of the `dask.distributed` framework (like distributed cores). They don't actually have to be used and dask will automatically use local resources. However, `dask.distributed` offers lots of other functionality such as the dashboard.\n",
    "\n",
    "* Dask `Client` are used to communicate with the workers in a cluster (via a `Scheduler`). \n",
    "\n",
    "The easiest way to make a new `Cluster` on your VM and connect to it with a `Client`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad8152-18fd-483a-a7aa-fa3c6d52eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f344cc6f-3e7b-401b-96c7-ccc1f9145cf6",
   "metadata": {},
   "source": [
    "* Make sure the close the cluster using `cluster.close()` before creating a new one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fcc759-b32d-4685-be5e-7738d1308755",
   "metadata": {},
   "source": [
    "## 2. Basic Use of Dask Array\n",
    "\n",
    "* Dask is pretty good at parallelizing and chunking any operations that can be done using typical numpy methods. \n",
    "* Most numpy methods that can be called from the main module (e.g. np.sum, np.mean, np.max) also have a dask array equivalent. \n",
    "* Any array you apply these methods to will be computed in chunks and lazily until you want to compute\n",
    "\n",
    "Start by importing dask array and some other things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2709efc5-1a7c-4085-8a14-3c2b76685f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f09a5-e3f1-402c-9735-65131696059d",
   "metadata": {},
   "source": [
    "Make a big array of random values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3836d34c-1be2-447e-af88-d36853f5465c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 7.45 GiB </td>\n",
       "                        <td> 781.25 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1000, 1000, 1000) </td>\n",
       "                        <td> (1000, 10, 10) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 10000 Tasks </td>\n",
       "                        <td> 10000 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"250\" height=\"240\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"6\" x2=\"80\" y2=\"76\" />\n",
       "  <line x1=\"10\" y1=\"12\" x2=\"80\" y2=\"82\" />\n",
       "  <line x1=\"10\" y1=\"18\" x2=\"80\" y2=\"88\" />\n",
       "  <line x1=\"10\" y1=\"25\" x2=\"80\" y2=\"95\" />\n",
       "  <line x1=\"10\" y1=\"31\" x2=\"80\" y2=\"101\" />\n",
       "  <line x1=\"10\" y1=\"37\" x2=\"80\" y2=\"107\" />\n",
       "  <line x1=\"10\" y1=\"43\" x2=\"80\" y2=\"113\" />\n",
       "  <line x1=\"10\" y1=\"50\" x2=\"80\" y2=\"120\" />\n",
       "  <line x1=\"10\" y1=\"56\" x2=\"80\" y2=\"126\" />\n",
       "  <line x1=\"10\" y1=\"62\" x2=\"80\" y2=\"132\" />\n",
       "  <line x1=\"10\" y1=\"68\" x2=\"80\" y2=\"138\" />\n",
       "  <line x1=\"10\" y1=\"75\" x2=\"80\" y2=\"146\" />\n",
       "  <line x1=\"10\" y1=\"81\" x2=\"80\" y2=\"152\" />\n",
       "  <line x1=\"10\" y1=\"87\" x2=\"80\" y2=\"158\" />\n",
       "  <line x1=\"10\" y1=\"93\" x2=\"80\" y2=\"164\" />\n",
       "  <line x1=\"10\" y1=\"100\" x2=\"80\" y2=\"171\" />\n",
       "  <line x1=\"10\" y1=\"106\" x2=\"80\" y2=\"177\" />\n",
       "  <line x1=\"10\" y1=\"112\" x2=\"80\" y2=\"183\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"80\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,190.58823529411765 10.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"200\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"16\" y1=\"0\" x2=\"86\" y2=\"70\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"92\" y2=\"70\" />\n",
       "  <line x1=\"28\" y1=\"0\" x2=\"98\" y2=\"70\" />\n",
       "  <line x1=\"35\" y1=\"0\" x2=\"105\" y2=\"70\" />\n",
       "  <line x1=\"41\" y1=\"0\" x2=\"111\" y2=\"70\" />\n",
       "  <line x1=\"47\" y1=\"0\" x2=\"117\" y2=\"70\" />\n",
       "  <line x1=\"53\" y1=\"0\" x2=\"123\" y2=\"70\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"130\" y2=\"70\" />\n",
       "  <line x1=\"66\" y1=\"0\" x2=\"136\" y2=\"70\" />\n",
       "  <line x1=\"72\" y1=\"0\" x2=\"142\" y2=\"70\" />\n",
       "  <line x1=\"78\" y1=\"0\" x2=\"148\" y2=\"70\" />\n",
       "  <line x1=\"85\" y1=\"0\" x2=\"156\" y2=\"70\" />\n",
       "  <line x1=\"91\" y1=\"0\" x2=\"162\" y2=\"70\" />\n",
       "  <line x1=\"97\" y1=\"0\" x2=\"168\" y2=\"70\" />\n",
       "  <line x1=\"103\" y1=\"0\" x2=\"174\" y2=\"70\" />\n",
       "  <line x1=\"110\" y1=\"0\" x2=\"181\" y2=\"70\" />\n",
       "  <line x1=\"116\" y1=\"0\" x2=\"187\" y2=\"70\" />\n",
       "  <line x1=\"122\" y1=\"0\" x2=\"193\" y2=\"70\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"200\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 200.58823529411765,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"200\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"76\" x2=\"200\" y2=\"76\" />\n",
       "  <line x1=\"80\" y1=\"82\" x2=\"200\" y2=\"82\" />\n",
       "  <line x1=\"80\" y1=\"88\" x2=\"200\" y2=\"88\" />\n",
       "  <line x1=\"80\" y1=\"95\" x2=\"200\" y2=\"95\" />\n",
       "  <line x1=\"80\" y1=\"101\" x2=\"200\" y2=\"101\" />\n",
       "  <line x1=\"80\" y1=\"107\" x2=\"200\" y2=\"107\" />\n",
       "  <line x1=\"80\" y1=\"113\" x2=\"200\" y2=\"113\" />\n",
       "  <line x1=\"80\" y1=\"120\" x2=\"200\" y2=\"120\" />\n",
       "  <line x1=\"80\" y1=\"126\" x2=\"200\" y2=\"126\" />\n",
       "  <line x1=\"80\" y1=\"132\" x2=\"200\" y2=\"132\" />\n",
       "  <line x1=\"80\" y1=\"138\" x2=\"200\" y2=\"138\" />\n",
       "  <line x1=\"80\" y1=\"146\" x2=\"200\" y2=\"146\" />\n",
       "  <line x1=\"80\" y1=\"152\" x2=\"200\" y2=\"152\" />\n",
       "  <line x1=\"80\" y1=\"158\" x2=\"200\" y2=\"158\" />\n",
       "  <line x1=\"80\" y1=\"164\" x2=\"200\" y2=\"164\" />\n",
       "  <line x1=\"80\" y1=\"171\" x2=\"200\" y2=\"171\" />\n",
       "  <line x1=\"80\" y1=\"177\" x2=\"200\" y2=\"177\" />\n",
       "  <line x1=\"80\" y1=\"183\" x2=\"200\" y2=\"183\" />\n",
       "  <line x1=\"80\" y1=\"190\" x2=\"200\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"86\" y1=\"70\" x2=\"86\" y2=\"190\" />\n",
       "  <line x1=\"92\" y1=\"70\" x2=\"92\" y2=\"190\" />\n",
       "  <line x1=\"98\" y1=\"70\" x2=\"98\" y2=\"190\" />\n",
       "  <line x1=\"105\" y1=\"70\" x2=\"105\" y2=\"190\" />\n",
       "  <line x1=\"111\" y1=\"70\" x2=\"111\" y2=\"190\" />\n",
       "  <line x1=\"117\" y1=\"70\" x2=\"117\" y2=\"190\" />\n",
       "  <line x1=\"123\" y1=\"70\" x2=\"123\" y2=\"190\" />\n",
       "  <line x1=\"130\" y1=\"70\" x2=\"130\" y2=\"190\" />\n",
       "  <line x1=\"136\" y1=\"70\" x2=\"136\" y2=\"190\" />\n",
       "  <line x1=\"142\" y1=\"70\" x2=\"142\" y2=\"190\" />\n",
       "  <line x1=\"148\" y1=\"70\" x2=\"148\" y2=\"190\" />\n",
       "  <line x1=\"156\" y1=\"70\" x2=\"156\" y2=\"190\" />\n",
       "  <line x1=\"162\" y1=\"70\" x2=\"162\" y2=\"190\" />\n",
       "  <line x1=\"168\" y1=\"70\" x2=\"168\" y2=\"190\" />\n",
       "  <line x1=\"174\" y1=\"70\" x2=\"174\" y2=\"190\" />\n",
       "  <line x1=\"181\" y1=\"70\" x2=\"181\" y2=\"190\" />\n",
       "  <line x1=\"187\" y1=\"70\" x2=\"187\" y2=\"190\" />\n",
       "  <line x1=\"193\" y1=\"70\" x2=\"193\" y2=\"190\" />\n",
       "  <line x1=\"200\" y1=\"70\" x2=\"200\" y2=\"190\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 200.58823529411765,70.58823529411765 200.58823529411765,190.58823529411765 80.58823529411765,190.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"140.588235\" y=\"210.588235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1000</text>\n",
       "  <text x=\"220.588235\" y=\"130.588235\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,220.588235,130.588235)\">1000</text>\n",
       "  <text x=\"35.294118\" y=\"175.294118\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,175.294118)\">1000</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<random_sample, shape=(1000, 1000, 1000), dtype=float64, chunksize=(1000, 10, 10), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = da.random.random((1000, 1000, 1000), chunks = [-1, 10, 10])\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7fa14-ea3b-4473-a2f6-3585fe47a926",
   "metadata": {},
   "source": [
    "* This is a huge 1000 x 1000 x 1000 array of random values, but none of them have been computed yet. \n",
    "* The array represents an instruction. \n",
    "* The array is chunked into 1000 x 10 x 10 cubes (the -1 takes the whole dimension). \n",
    "* By looking at the array in Jupyter, we can see the size of the whole computed array (75Gb ish) and each chunks (~8Mb ish).\n",
    "\n",
    "While the whole array can't be easily stored in memory without a large computer, we can still apply operations on it and, if done wisely, we can handle their outputs much more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c576a64-9d5e-4827-ae55-94261e994a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 7.63 MiB </td>\n",
       "                        <td> 800 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1000, 1000) </td>\n",
       "                        <td> (10, 10) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 30000 Tasks </td>\n",
       "                        <td> 10000 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"120\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"120\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"18\" x2=\"120\" y2=\"18\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"120\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"120\" y2=\"37\" />\n",
       "  <line x1=\"0\" y1=\"43\" x2=\"120\" y2=\"43\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"120\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"120\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"62\" x2=\"120\" y2=\"62\" />\n",
       "  <line x1=\"0\" y1=\"68\" x2=\"120\" y2=\"68\" />\n",
       "  <line x1=\"0\" y1=\"75\" x2=\"120\" y2=\"75\" />\n",
       "  <line x1=\"0\" y1=\"81\" x2=\"120\" y2=\"81\" />\n",
       "  <line x1=\"0\" y1=\"87\" x2=\"120\" y2=\"87\" />\n",
       "  <line x1=\"0\" y1=\"93\" x2=\"120\" y2=\"93\" />\n",
       "  <line x1=\"0\" y1=\"100\" x2=\"120\" y2=\"100\" />\n",
       "  <line x1=\"0\" y1=\"106\" x2=\"120\" y2=\"106\" />\n",
       "  <line x1=\"0\" y1=\"112\" x2=\"120\" y2=\"112\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"6\" y1=\"0\" x2=\"6\" y2=\"120\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"120\" />\n",
       "  <line x1=\"18\" y1=\"0\" x2=\"18\" y2=\"120\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" />\n",
       "  <line x1=\"31\" y1=\"0\" x2=\"31\" y2=\"120\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"120\" />\n",
       "  <line x1=\"43\" y1=\"0\" x2=\"43\" y2=\"120\" />\n",
       "  <line x1=\"50\" y1=\"0\" x2=\"50\" y2=\"120\" />\n",
       "  <line x1=\"56\" y1=\"0\" x2=\"56\" y2=\"120\" />\n",
       "  <line x1=\"62\" y1=\"0\" x2=\"62\" y2=\"120\" />\n",
       "  <line x1=\"68\" y1=\"0\" x2=\"68\" y2=\"120\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"120\" />\n",
       "  <line x1=\"81\" y1=\"0\" x2=\"81\" y2=\"120\" />\n",
       "  <line x1=\"87\" y1=\"0\" x2=\"87\" y2=\"120\" />\n",
       "  <line x1=\"93\" y1=\"0\" x2=\"93\" y2=\"120\" />\n",
       "  <line x1=\"100\" y1=\"0\" x2=\"100\" y2=\"120\" />\n",
       "  <line x1=\"106\" y1=\"0\" x2=\"106\" y2=\"120\" />\n",
       "  <line x1=\"112\" y1=\"0\" x2=\"112\" y2=\"120\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1000</text>\n",
       "  <text x=\"140.000000\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,60.000000)\">1000</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<sum-aggregate, shape=(1000, 1000), dtype=float64, chunksize=(10, 10), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the sum over the first axis:\n",
    "array_sum  = da.sum( array, axis=0 )\n",
    "array_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f96f5d-0367-4b03-b9fe-ee6fe1992d2a",
   "metadata": {},
   "source": [
    "These arrays have still not been computed, so lets do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36b77229-6c39-4d51-855c-5f4303469886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_computed = array_sum.compute()\n",
    "type(array_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb97d1-d0e1-48f4-9cb9-9e85843fe5fb",
   "metadata": {},
   "source": [
    "The computed array is now a numpy array. We can also string operations together:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a20780ac-a32d-47a8-bf16-41184b45033e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 8 B </td>\n",
       "                        <td> 8.0 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> () </td>\n",
       "                        <td> () </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 43364 Tasks </td>\n",
       "                        <td> 1 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        \n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<mean_agg-aggregate, shape=(), dtype=float64, chunksize=(), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_mean_sum = da.mean( array_sum )\n",
    "array_mean_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273a1be-5b87-402d-8890-719374553c1f",
   "metadata": {},
   "source": [
    "Above, I called `.compute()` directly onto the dask array. There are some other options at this point:\n",
    "\n",
    "* `dask.compute( array )`. I think this is basically the same as calling .compute() directly onto the array.\n",
    "* `client.compute( array )`. This will return a `Future` object, having submitted the job to the cluster using the client. A future object will be carrying out the computation in the background. You can interrogate this object to see whether or not the computation has finished yet (it will be *pending* or *finalized*). This returns a single future object for the result, which is stored in its entirety on one worked. Therefore this is the option to use for small results.\n",
    "* `client.persist( array )`. This is similar to client.compute() in that it submits all of the tasks to the cluster. However, it doesn't gather the resulting future into one place like client.compute() does. Instead, the result will stay distributed over workers. This is a better option for bigger results.\n",
    "\n",
    "These routines can also be passed lists of array, tasks or delayed objects. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ef673e-9ac7-4c95-968e-e546630a9beb",
   "metadata": {},
   "source": [
    "## 3. Point-by-point analysis\n",
    "\n",
    "Sometimes you need more control over the analysis that can't be provided by dask.array methods, e.g. doing a time series analysis at every point in a geospatial domain. In these cases, I have found two useful methods: `map_blocks()` and using lists of delayed objects.\n",
    "\n",
    "### 3.1 Map_blocks()\n",
    "\n",
    "* This will apply a function to all and each chunk of a dask array in parallel.\n",
    "* A function will be applied across chunks, and then the results 'stitched' back together into one dask array.\n",
    "* It has a constraint: the returned 'stitched' array should have the same number of dimensions as the input array.\n",
    "* Some thought must be put into the function applied to make sure the above constraint is satisfied. In many cases it is easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c848d290-d50e-4405-abdd-67b99a07530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things\n",
    "import dask.array as da\n",
    "import dask\n",
    "import numpy as np\n",
    "\n",
    "# Make a new BIG array of random numbers\n",
    "array = da.random.random((1000, 1000, 1000), chunks = [-1, 10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0983250a-6891-4197-96dd-4efb874daae8",
   "metadata": {},
   "source": [
    "In the above array, let's pretend that the first dimension is time and we want to do some sort of analysis along the time dimension, at every point in the domain. To apply map_blocks() correctly, I have only chunked the \"horizontal\" axes.\n",
    "\n",
    "Define a function to apply at each point. The following function will calculate the 10 largest elements of each time series. The eventual array will then be of shape 10 x 1000 x 1000, with the first dimension being the largest elements. In this example, I have applied a sorting method to each time series independently using numpy, although of course this could be done to a whole chunk by specifying an axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3f3ccfde-3710-4e4c-b5be-9539f912dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_me_to_each_chunk(chunk):\n",
    "    \n",
    "    # Get number of times, rows and cols in this chunk\n",
    "    n_time, n_r, n_c = chunk.shape\n",
    "    n_pts = n_r*n_c\n",
    "    \n",
    "    # Flatten the chunk in the horizontal dimension\n",
    "    chunkF = chunk.reshape((n_time, n_pts))\n",
    "    \n",
    "    # Define an empty output array\n",
    "    top10 = np.zeros((10, n_pts))*np.nan\n",
    "    \n",
    "    # Loop over each \"horizontal\" point of the chunk\n",
    "    for ii in range(n_pts):\n",
    "        \n",
    "        # Pull out time series for this point and sort\n",
    "        sorted_data = np.sort( chunkF[:, ii] )\n",
    "        \n",
    "        # Get top 10 values and put into output array\n",
    "        top10[:, ii] = sorted_data[::-1][:10]\n",
    "        \n",
    "    # Reshape top10 to have the same dimension as the input chunk and return\n",
    "    return top10.reshape((10, n_r, n_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f417d6ef-995c-416f-af6c-24795c5b2343",
   "metadata": {},
   "source": [
    "Now we can use `map_blocks()`. This routine takes the function as an argument, and then any arguments taken by the function. In our case, this is only a chunk array. For this arguments, we pass it the full dask array and dask will handle the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "90309a5f-f3ce-4838-9735-516fecfc3654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000, 1000)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call map_blocks\n",
    "top10 = da.map_blocks(apply_me_to_each_chunk, array, dtype=int)\n",
    "\n",
    "# Compute the result in some way\n",
    "top10 = top10.compute()\n",
    "\n",
    "top10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94daaac-6a8e-4282-8e19-ff605a9e92bc",
   "metadata": {},
   "source": [
    "* Of course, this doesn't have to be computed immediately. It could be subjected to further analysis or written to files such as .zarr or .netcdf.\n",
    "* There are ways of changing the shape and dimension of the output array. See the map_blocks docs for examples (maybe I'll add these here at some point).\n",
    "* If you only want to process one time series per core you could avoid the loop in the function above. Just chunks along the 2nd and 3rd dimensions with chunk sizes of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf9641-5b7f-4c9d-9d8b-ca7cae380e50",
   "metadata": {},
   "source": [
    "### 3.2 Computation of Delayed Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b64382c-48ab-4bfe-8fcd-e8988a7abe6f",
   "metadata": {},
   "source": [
    "Sometimes map_blocks might not work, for example if the resulting outputs cannot be easily placed into an array. In this case, we can turn the chunks of a dask array into delayed objects and apply a function to each.\n",
    "\n",
    "Lets define another function. This will return all elements of the chunk over 0.99. As this will be a different sized array for each chunk, we can't use map_blocks as easily. (Of course there are functions such as da.where() or other indexing methods, but this is just an example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4f581250-37a1-4677-8d2d-bb75b437249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_me_to_each_delayed_chunk(delayed_chunk):\n",
    "    \n",
    "    # Pull out all values over 0.98 in the chunk\n",
    "    over_threshold = delayed_chunk[ delayed_chunk > 0.99 ]\n",
    "    \n",
    "    return over_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a891a-170b-4043-b86c-d8d58374391b",
   "metadata": {},
   "source": [
    "Now create a random array and turn it into a list of delayed chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "51f6ff6f-962f-48c8-a15f-385616110445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 100)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Import things\n",
    "import dask.array as da\n",
    "import dask\n",
    "import numpy as np\n",
    "\n",
    "# Make a new BIG array of random numbers\n",
    "array = da.random.random((1000, 1000, 1000), chunks = [-1, 10, 10])\n",
    "\n",
    "# Turn into delayed objects, with shape 1x100x100\n",
    "delayed_array = array.to_delayed()\n",
    "print( delayed_array.shape )\n",
    "\n",
    "# Stack these delayed arrays\n",
    "delayed_array = delayed_array.ravel()\n",
    "print( delayed_array.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6b3d8-ad9b-4a16-8779-c306f22f7e4f",
   "metadata": {},
   "source": [
    "Now loop over these delayed chunks and aplpy the function we wrote above. The result will be a further list of delayed objects that are waiting to be computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "854d5b77-55bc-4e90-8f9a-3079bbbb8ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('getitem-1ecda444836f9e8ff7dbebc78308deae')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_threshold = [ apply_me_to_each_delayed_chunk(dd) for dd in delayed_array ]\n",
    "over_threshold[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b4afd7-f10d-477a-8957-e11a591ff6d8",
   "metadata": {},
   "source": [
    "Now compute. In this case I have used persist for no particular reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8ba24ddc-90cb-4e3d-8984-231ee01c11f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9900639 , 0.99609172, 0.9907704 , ..., 0.99338078, 0.99558568,\n",
       "       0.99130166])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed = client.persist(over_threshold)\n",
    "computed[0].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b04ad9e-3dda-4a19-bd2c-8284b02074af",
   "metadata": {},
   "source": [
    "## 4. Input/Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9390170-e375-4b0f-b4ff-7f6f1f82ffe7",
   "metadata": {},
   "source": [
    "### 4.1 Input with Xarray\n",
    "\n",
    "Xarray is a useful library for interaction between netCDF files and dask. Files are read into xarray Datasets and variables are represented by xarray DataArrays. When opening a netCDF file, if you specify the `chunks` argument then the data will be read automatically (and lazily) into a dask array. This means the data stays on the storage disk until needed. When needed, chunks will be read to memory accordingly. This can be a little slower than reading all data at once, but helps combat memory issues for big datasets.\n",
    "\n",
    "```\n",
    "import xarray as xr\n",
    "filename = \"<example_filename>\"\n",
    "dataset = xr.open_dataset( filename, chunks={'time':-1, 'lat':100, 'lon':100})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca583eed-ffa0-4471-b37a-515a3d9473c2",
   "metadata": {},
   "source": [
    "The underlying dask array can be accessed from a data array using the `.data` call. e.g.\n",
    "\n",
    "```\n",
    "variable = dataset['variable_name']\n",
    "dask_array = variable.data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af499cb4-ddbc-47bd-bf2c-2fd4581b79ba",
   "metadata": {},
   "source": [
    "The the dask methods described in previous sections can be easily applied to this. Note that this dask array comes preset with additional tasks for loading in the data.\n",
    "\n",
    "Often, you may not need to convert an xarray dataset or array into a dask array first, as xarray comes with many dask-type functions that can be applied straight to the dataset. This actually includes most of the routines in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e07990c-edfe-4038-ae85-c62af49ff851",
   "metadata": {},
   "source": [
    "### 4.2 Output with Xarray\n",
    "\n",
    "If your data is in an xarray dataset, whether computed or not, it can be written to netCDF using the `to_netcdf()` function. If the data inside the dataset is an uncomputed dask array, then data should be written on a chunkwise basis. This is useful if the computed data is also very large and you don't want it read to memory. Call the analysis lazily, then write it to file. Xarray can also be used to write to zarr in a similar way by using the `to_zarr()` function instead.\n",
    "\n",
    "In the case where you are working with dask arrays and the data is not in an xarray object you can quickly write the data to a .zarr file using Dask's own `dask.array.to_zarr()` function. \n",
    "\n",
    "If you want to write to netcdf, you can quickly put the data into an xarray DataArray first and then call `to_netcdf()`. For example, using the top10 array calculated in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b85d7-d2ca-40e6-a4d5-660b3e277daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_array = xr.DataArray(top10, dims=['top10','r','c'])\n",
    "output_array.to_netcdf('output_file.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
